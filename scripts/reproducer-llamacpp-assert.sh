#!/bin/bash
/build/llama.cpp/bin/llama-cli \
        --log-file /tmp/llamacpp-Qwen3-30B-A3B-Q8_K_XL.log \
        --hf-repo unsloth/Qwen3-30B-A3B-GGUF:Q4_K_XL \
        --override-tensor '([0-9]+).ffn_.*_exps.=CPU' \
        --n-gpu-layers 48 \
        --jinja \
        --cache-type-k q8_0 \
        --ctx-size 32768 \
        --samplers "top_k;dry;min_p;temperature;top_p" \
        --min-p 0.005 \
        --top-p 0.97 \
        --top-k 40 \
        --temp 0.7 \
        --dry-multiplier 0.7 \
        --dry-allowed-length 4 \
        --dry-penalty-last-n 2048 \
        --presence-penalty 0.05 \
        --frequency-penalty 0.005 \
        --repeat-penalty 1.01 \
        --repeat-last-n 16 \
        --verbose \
        --file generic-prompt-for-testing-1906words.txt
