{
    "$schema": "https://opencode.ai/config.json",
    "provider": {
        "llamaswap": {
            "name": "Local llama-swap",
            "npm" : "@ai-sdk/openai-compatible",
            "options": {
                "baseURL": "http://host.docker.internal:8688/v1",
                "apiKey": "{env:LLAMA_API_KEY}",
            },
            "models": {
                "vllm-Qwen3-Coder-30B": {
                    "name": "vllm-Qwen3-Coder-30B",
                    "limit": {
                        "context": 48000,
                        "output": 8000
                    }
                },
                "vllm-gpt-oss-20b": {
                    "name": "vllm-gpt-oss-20b",
                    "limit": {
                        "context": 32768,
                        "output": 8000
                    }
                }
            }
        }
    }
}
