  llamacpp-Qwen3-30B-A3B-cpu:
    cmd: |
      /opt/llama.cpp/build/bin/llama-server
        --log-file /logs/llamacpp-Qwen3-30B-A3B-Q8_K_XL.log
        --port 8710
        --hf-repo bartowski/Qwen_Qwen3-30B-A3B-GGUF:Q8_0
        # 32.5GB
        --override-tensor '([0-9]+).ffn_.*_exps.=CPU'
        --n-gpu-layers 48
        # of 48
        --jinja
        --cache-type-k q8_0
        --ctx-size 32768
        --samplers 'top_k;dry;min_p;temperature;top_p'
        # vain attempt to capture both thinking/non-thinking
        --min-p 0.005
        --top-p 0.97
        --top-k 40
        --temp 0.7
        --dry-multiplier 0.7
        --dry-allowed-length 4
        --dry-penalty-last-n 2048
        --presence-penalty 0.05
        --frequency-penalty 0.005
        --repeat-penalty 1.01
        --repeat-last-n 16
        --verbose
    proxy: http://127.0.0.1:8710
    ttl: 3600
